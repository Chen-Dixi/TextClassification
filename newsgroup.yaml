train:
  min_step: 40000 # minimum steps to run. run epochs until it exceeds the minStep
  lr: 0.01 # learning rate for new layers. learning rate for finetune is 1/10 of lr
  lr_embedding: 0.001 
  weight_decay: 0.0005
  momentum: 0.9
  epochs: 50

misc:
  gpus: 1 

test:
  test_interval: 500 # interval of two continuous test phase
  test_only: False # test a given model and exit
  resume_file: '' # model to test

model:
  vocab_size: 299567
  embedding_dim: 300 #词向量维度
  inception_dim: 200 #inception卷积核数
  content_seq_len: 5000 #描述长度 nn.MaxPool1d(opt.content_seq_len)
  linear_hidden_size: 256
  num_classes: 20
  pretrain_embedding: True
  embedding_path: 'data/embedding.npz'
  static: False #是否让Embedding保持不动
  
data:
  train_dir: 'data/20_newsgroups_npz'
  test_dir: 'data/20_newsgroups_npz'
  dataloader:
    batch_size: 64
  train_val_proportion: 0.8